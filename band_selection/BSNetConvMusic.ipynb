{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ucalyptus/BS-Nets-Implementation-Pytorch/blob/master/Pytorch_BSNetConv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "wY0-W1WbCRmu",
    "outputId": "682718f9-d090-46fe-ac6b-7ccd585e3f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kornia in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (0.7.0)\r\n",
      "Requirement already satisfied: torch>=1.9.1 in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from kornia) (2.0.1)\r\n",
      "Requirement already satisfied: packaging in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from kornia) (23.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (4.4.0)\r\n",
      "Requirement already satisfied: networkx in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (2.6.3)\r\n",
      "Requirement already satisfied: jinja2 in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (3.1.2)\r\n",
      "Requirement already satisfied: filelock in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (3.12.0)\r\n",
      "Requirement already satisfied: sympy in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (1.12)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from jinja2->torch>=1.9.1->kornia) (2.1.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aySwtTTLdACS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from scipy import io \n",
    "import torch.utils.data\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \n",
    "                      (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "O_vZ-V7Cfffp",
    "outputId": "23f393e8-3cce-4f81-ea7f-236fd560b9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spectral in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (0.23.1)\n",
      "Requirement already satisfied: numpy in /Users/luisreyes/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages (from spectral) (1.24.3)\n",
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2023-08-22 19:21:55--  https://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
      "Resolving www.ehu.eus (www.ehu.eus)... 2001:720:1410::65, 158.227.0.65\n",
      "Connecting to www.ehu.eus (www.ehu.eus)|2001:720:1410::65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5953527 (5.7M)\n",
      "Saving to: 'Indian_pines_corrected.mat.11'\n",
      "\n",
      "Indian_pines_correc 100%[===================>]   5.68M  2.65MB/s    in 2.1s    \n",
      "\n",
      "2023-08-22 19:21:57 (2.65 MB/s) - 'Indian_pines_corrected.mat.11' saved [5953527/5953527]\n",
      "\n",
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2023-08-22 19:21:57--  https://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat\n",
      "Resolving www.ehu.eus (www.ehu.eus)... 2001:720:1410::65, 158.227.0.65\n",
      "Connecting to www.ehu.eus (www.ehu.eus)|2001:720:1410::65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1125 (1.1K)\n",
      "Saving to: 'Indian_pines_gt.mat.11'\n",
      "\n",
      "Indian_pines_gt.mat 100%[===================>]   1.10K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-08-22 19:21:58 (18.8 MB/s) - 'Indian_pines_gt.mat.11' saved [1125/1125]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spectral\n",
    "if not (os.path.isfile('/content/Indian_pines_corrected.mat')):\n",
    "  !wget http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
    "if not (os.path.isfile('/content/Indian_pines_gt.mat')):\n",
    "  !wget http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iALoEpq56YRP",
    "outputId": "14efb40f-1dc6-4fab-cd89-32d9198869a0"
   },
   "outputs": [],
   "source": [
    "from music_2d_dataset import MUSIC2DDataset\n",
    "import music_2d_dataset\n",
    "path2d = \"MUSIC2D_HDF5\"\n",
    "path3d = \"MUSIC3D_HDF5\"\n",
    "transform = music_2d_dataset.JointTransform2D(crop=(7,7), p_flip=0, color_jitter_params=None, long_mask=True)\n",
    "data_train = MUSIC2DDataset(\n",
    "        path2d=path2d, path3d=path3d,\n",
    "        partition=\"train\", \n",
    "        spectrum=\"fullSpectrum\",\n",
    "        transform=transform, \n",
    "        full_dataset=True, \n",
    ")\n",
    "train_loader = DataLoader(data_train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EyGgFaKF5J51",
    "outputId": "ab64d306-99ce-41de-d74e-6dbafec3f79e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 7, 7])\n",
      "437\n"
     ]
    }
   ],
   "source": [
    "print(data_train[0][\"image\"].shape)\n",
    "print(data_train.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJY-1XbQbb64"
   },
   "outputs": [],
   "source": [
    "\n",
    "class BSNET_Conv(nn.Module):\n",
    "\n",
    "    def __init__(self,):\n",
    "      \n",
    "        super(BSNET_Conv, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "        \tnn.Conv2d(128,64,(3,3),1,0),\n",
    "        \tnn.ReLU(True))\n",
    "\n",
    "        self.conv1_1 = nn.Sequential(\n",
    "        \tnn.Conv2d(128,128,(3,3),1,0),\n",
    "        \tnn.ReLU(True))\n",
    "        self.conv1_2 = nn.Sequential(\n",
    "        \tnn.Conv2d(128,64,(3,3),1,0),\n",
    "        \tnn.ReLU(True))\n",
    "        \n",
    "        self.deconv1_2 = nn.Sequential(\n",
    "        \tnn.ConvTranspose2d(64,64,(3,3),1,0),\n",
    "        \tnn.ReLU(True))\n",
    "        \n",
    "        self.deconv1_1 = nn.Sequential(\n",
    "        \tnn.ConvTranspose2d(64,128,(3,3),1,0),\n",
    "        \tnn.ReLU(True))\n",
    "\n",
    "        self.conv2_1 = nn.Sequential(\n",
    "        \tnn.Conv2d(128,128,(1,1),1,0),\n",
    "        \tnn.Sigmoid())\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "        \tnn.Linear(64,128),\n",
    "        \tnn.ReLU(True))\n",
    "        self.fc2 = nn.Sequential(\n",
    "        \tnn.Linear(128,128),\n",
    "        \tnn.Sigmoid())\n",
    "        self.gp=nn.AvgPool2d(5)\n",
    "    \n",
    "        \n",
    "    def BAM(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        \n",
    "        x = self.gp(x)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1,64)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = x.view(-1,1,1,128)\n",
    "        x = x.permute(0,3,1,2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def RecNet(self,x):\n",
    "\n",
    "      x = self.conv1_1(x)\n",
    "      \n",
    "      x = self.conv1_2(x)\n",
    "      \n",
    "      x = self.deconv1_2(x)\n",
    "      \n",
    "      x = self.deconv1_1(x)\n",
    "      \n",
    "      x = self.conv2_1(x)\n",
    "      \n",
    "      return x\n",
    "      \n",
    "      \n",
    "\n",
    "    def forward(self,x):\n",
    "      \n",
    "      BRW = self.BAM(x)\n",
    "      \n",
    "      x = x*BRW\n",
    "      ret = self.RecNet(x)\n",
    "      \n",
    "      return ret\n",
    "\n",
    "\n",
    "       \n",
    "model = BSNET_Conv().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "kNopEhPR45TA",
    "outputId": "59c1ad15-5638-4a3b-e670-6ecc63651f24"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (MPSFloatType) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m----> 2\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 76\u001b[0m, in \u001b[0;36mBSNET_Conv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 76\u001b[0m   BRW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBAM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m   x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m*\u001b[39mBRW\n\u001b[1;32m     79\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRecNet(x)\n",
      "Cell \u001b[0;32mIn[8], line 41\u001b[0m, in \u001b[0;36mBSNET_Conv.BAM\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mBAM\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 41\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgp(x)\n\u001b[1;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m64\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (MPSFloatType) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(128,7,7),batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8WRFPqzCpQJ"
   },
   "outputs": [],
   "source": [
    "top = 30\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=([0.9, 0.999]), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rrUBTJ4S40eD",
    "outputId": "4a86368f-cbb9-4f58-a46d-6d88750a8166",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/437 (0%)]\tLoss: 0.055775\n",
      "SSIM: 0.07121466100215912\n",
      "PSNR: -81.76298522949219\n",
      "Train Epoch: 0 [224/437 (50%)]\tLoss: 0.468695\n",
      "SSIM: 0.4480150043964386\n",
      "PSNR: -72.60550689697266\n",
      "Top 30 bands with Entropy -> [44, 15, 114, 13, 16, 66, 96, 97, 72, 107, 60, 18, 46, 37, 101, 124, 29, 47, 109, 31, 118, 110, 40, 8, 22, 10, 50, 74, 20, 30]\n",
      "Train Epoch: 1 [0/437 (0%)]\tLoss: 0.467390\n",
      "SSIM: 0.45326054096221924\n",
      "PSNR: -72.68417358398438\n",
      "Train Epoch: 1 [224/437 (50%)]\tLoss: 0.468801\n",
      "SSIM: 0.44962364435195923\n",
      "PSNR: -72.68953704833984\n",
      "Top 30 bands with Entropy -> [15, 44, 66, 124, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 18, 8, 29, 101, 31, 74, 40, 110, 22, 30, 50, 10, 118, 38]\n",
      "Train Epoch: 2 [0/437 (0%)]\tLoss: 0.461410\n",
      "SSIM: 0.4593110978603363\n",
      "PSNR: -72.74346160888672\n",
      "Train Epoch: 2 [224/437 (50%)]\tLoss: 0.468019\n",
      "SSIM: 0.45439186692237854\n",
      "PSNR: -72.62928771972656\n",
      "Top 30 bands with Entropy -> [15, 44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 18, 29, 101, 31, 74, 40, 110, 22, 30, 50, 10, 118, 38]\n",
      "Train Epoch: 3 [0/437 (0%)]\tLoss: 0.464024\n",
      "SSIM: 0.4548526704311371\n",
      "PSNR: -72.67095184326172\n",
      "Train Epoch: 3 [224/437 (50%)]\tLoss: 0.469626\n",
      "SSIM: 0.4593466818332672\n",
      "PSNR: -72.56195831298828\n",
      "Top 30 bands with Entropy -> [15, 44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 18, 29, 101, 31, 74, 40, 110, 22, 30, 50, 10, 38, 118]\n",
      "Train Epoch: 4 [0/437 (0%)]\tLoss: 0.463336\n",
      "SSIM: 0.45772138237953186\n",
      "PSNR: -72.86621856689453\n",
      "Train Epoch: 4 [224/437 (50%)]\tLoss: 0.466583\n",
      "SSIM: 0.45650044083595276\n",
      "PSNR: -72.67691040039062\n",
      "Top 30 bands with Entropy -> [15, 44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 18, 29, 101, 31, 74, 40, 110, 22, 30, 50, 10, 118, 38]\n",
      "Train Epoch: 5 [0/437 (0%)]\tLoss: 0.466190\n",
      "SSIM: 0.4480845034122467\n",
      "PSNR: -72.84964752197266\n",
      "Train Epoch: 5 [224/437 (50%)]\tLoss: 0.469673\n",
      "SSIM: 0.45085766911506653\n",
      "PSNR: -72.62347412109375\n",
      "Top 30 bands with Entropy -> [15, 44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 46, 60, 8, 18, 29, 101, 31, 74, 40, 110, 22, 30, 50, 10, 38, 118]\n",
      "Train Epoch: 6 [0/437 (0%)]\tLoss: 0.464736\n",
      "SSIM: 0.45302262902259827\n",
      "PSNR: -72.82865905761719\n",
      "Train Epoch: 6 [224/437 (50%)]\tLoss: 0.469087\n",
      "SSIM: 0.4533182978630066\n",
      "PSNR: -72.75811004638672\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 18, 29, 101, 31, 74, 15, 110, 22, 40, 30, 50, 10, 118, 38]\n",
      "Train Epoch: 7 [0/437 (0%)]\tLoss: 0.473337\n",
      "SSIM: 0.45376452803611755\n",
      "PSNR: -72.47347259521484\n",
      "Train Epoch: 7 [224/437 (50%)]\tLoss: 0.462831\n",
      "SSIM: 0.4541700482368469\n",
      "PSNR: -72.83055877685547\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 97, 107, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 22, 40, 50, 30, 10, 118, 38, 79]\n",
      "Train Epoch: 8 [0/437 (0%)]\tLoss: 0.460837\n",
      "SSIM: 0.44854578375816345\n",
      "PSNR: -72.81719970703125\n",
      "Train Epoch: 8 [224/437 (50%)]\tLoss: 0.468356\n",
      "SSIM: 0.45134904980659485\n",
      "PSNR: -72.67138671875\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 97, 107, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 22, 40, 50, 30, 10, 118, 38, 79]\n",
      "Train Epoch: 9 [0/437 (0%)]\tLoss: 0.463013\n",
      "SSIM: 0.4435666501522064\n",
      "PSNR: -72.93328094482422\n",
      "Train Epoch: 9 [224/437 (50%)]\tLoss: 0.463894\n",
      "SSIM: 0.45455262064933777\n",
      "PSNR: -72.70159149169922\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 97, 107, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 22, 40, 30, 50, 10, 118, 38, 79]\n",
      "Train Epoch: 10 [0/437 (0%)]\tLoss: 0.466933\n",
      "SSIM: 0.4550560712814331\n",
      "PSNR: -72.64421081542969\n",
      "Train Epoch: 10 [224/437 (50%)]\tLoss: 0.459746\n",
      "SSIM: 0.45253658294677734\n",
      "PSNR: -72.72993469238281\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 22, 40, 50, 30, 10, 118, 38, 79]\n",
      "Train Epoch: 11 [0/437 (0%)]\tLoss: 0.464938\n",
      "SSIM: 0.45795193314552307\n",
      "PSNR: -72.69639587402344\n",
      "Train Epoch: 11 [224/437 (50%)]\tLoss: 0.466727\n",
      "SSIM: 0.445105642080307\n",
      "PSNR: -72.7147216796875\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 46, 60, 8, 29, 101, 18, 31, 74, 22, 110, 40, 50, 30, 10, 118, 38, 79]\n",
      "Train Epoch: 12 [0/437 (0%)]\tLoss: 0.463985\n",
      "SSIM: 0.45425841212272644\n",
      "PSNR: -72.74491882324219\n",
      "Train Epoch: 12 [224/437 (50%)]\tLoss: 0.465337\n",
      "SSIM: 0.4608997404575348\n",
      "PSNR: -72.62191009521484\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 22, 40, 50, 30, 10, 118, 38, 79]\n",
      "Train Epoch: 13 [0/437 (0%)]\tLoss: 0.463904\n",
      "SSIM: 0.4471074342727661\n",
      "PSNR: -72.86730194091797\n",
      "Train Epoch: 13 [224/437 (50%)]\tLoss: 0.467769\n",
      "SSIM: 0.4534969627857208\n",
      "PSNR: -72.50911712646484\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 97, 107, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 22, 40, 30, 50, 10, 118, 38, 79]\n",
      "Train Epoch: 14 [0/437 (0%)]\tLoss: 0.466938\n",
      "SSIM: 0.4469009339809418\n",
      "PSNR: -72.62846374511719\n",
      "Train Epoch: 14 [224/437 (50%)]\tLoss: 0.466542\n",
      "SSIM: 0.45456498861312866\n",
      "PSNR: -72.76533508300781\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 97, 107, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 22, 40, 50, 30, 10, 118, 38, 79]\n",
      "Train Epoch: 15 [0/437 (0%)]\tLoss: 0.467389\n",
      "SSIM: 0.44346028566360474\n",
      "PSNR: -72.94396209716797\n",
      "Train Epoch: 15 [224/437 (50%)]\tLoss: 0.467544\n",
      "SSIM: 0.4432065486907959\n",
      "PSNR: -72.72174072265625\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 97, 107, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 22, 40, 50, 30, 10, 118, 38, 79]\n",
      "Train Epoch: 16 [0/437 (0%)]\tLoss: 0.463750\n",
      "SSIM: 0.44426122307777405\n",
      "PSNR: -72.92123413085938\n",
      "Train Epoch: 16 [224/437 (50%)]\tLoss: 0.466000\n",
      "SSIM: 0.45421695709228516\n",
      "PSNR: -72.69429779052734\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 22, 40, 50, 30, 10, 38, 79, 118]\n",
      "Train Epoch: 17 [0/437 (0%)]\tLoss: 0.465883\n",
      "SSIM: 0.4503575563430786\n",
      "PSNR: -72.7525863647461\n",
      "Train Epoch: 17 [224/437 (50%)]\tLoss: 0.473258\n",
      "SSIM: 0.4496499300003052\n",
      "PSNR: -72.50731658935547\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 40, 22, 50, 10, 30, 79, 38, 20]\n",
      "Train Epoch: 18 [0/437 (0%)]\tLoss: 0.463368\n",
      "SSIM: 0.4452952742576599\n",
      "PSNR: -72.96293640136719\n",
      "Train Epoch: 18 [224/437 (50%)]\tLoss: 0.471143\n",
      "SSIM: 0.4438033401966095\n",
      "PSNR: -72.8499526977539\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 29, 101, 18, 31, 74, 110, 40, 50, 30, 10, 22, 79, 38, 20]\n",
      "Train Epoch: 19 [0/437 (0%)]\tLoss: 0.472348\n",
      "SSIM: 0.45994701981544495\n",
      "PSNR: -72.51519012451172\n",
      "Train Epoch: 19 [224/437 (50%)]\tLoss: 0.463355\n",
      "SSIM: 0.45587578415870667\n",
      "PSNR: -72.89733123779297\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 107, 97, 72, 47, 37, 96, 109, 60, 46, 8, 101, 29, 18, 31, 74, 110, 40, 50, 30, 10, 22, 79, 38, 20]\n",
      "Train Epoch: 20 [0/437 (0%)]\tLoss: 0.468521\n",
      "SSIM: 0.4584796726703644\n",
      "PSNR: -72.5811538696289\n",
      "Train Epoch: 20 [224/437 (50%)]\tLoss: 0.462379\n",
      "SSIM: 0.45649898052215576\n",
      "PSNR: -72.81744384765625\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 97, 107, 47, 72, 37, 96, 109, 60, 46, 8, 101, 29, 18, 31, 74, 110, 40, 50, 30, 10, 22, 79, 38, 20]\n",
      "Train Epoch: 21 [0/437 (0%)]\tLoss: 0.463367\n",
      "SSIM: 0.452282190322876\n",
      "PSNR: -72.68164825439453\n",
      "Train Epoch: 21 [224/437 (50%)]\tLoss: 0.472521\n",
      "SSIM: 0.4531601071357727\n",
      "PSNR: -72.52823638916016\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 107, 97, 47, 72, 37, 96, 109, 60, 46, 8, 101, 29, 18, 31, 74, 110, 40, 50, 30, 10, 22, 79, 38, 20]\n",
      "Train Epoch: 22 [0/437 (0%)]\tLoss: 0.467280\n",
      "SSIM: 0.4549403190612793\n",
      "PSNR: -72.77606201171875\n",
      "Train Epoch: 22 [224/437 (50%)]\tLoss: 0.474664\n",
      "SSIM: 0.4630895256996155\n",
      "PSNR: -72.42605590820312\n",
      "Top 30 bands with Entropy -> [44, 124, 66, 114, 16, 13, 97, 107, 72, 47, 37, 96, 109, 60, 46, 8, 101, 29, 18, 31, 74, 110, 40, 50, 30, 10, 22, 79, 38, 20]\n",
      "Train Epoch: 23 [0/437 (0%)]\tLoss: 0.470261\n",
      "SSIM: 0.44839540123939514\n",
      "PSNR: -72.72883605957031\n",
      "Train Epoch: 23 [224/437 (50%)]\tLoss: 0.460735\n",
      "SSIM: 0.45267608761787415\n",
      "PSNR: -72.87783813476562\n",
      "Top 30 bands with Entropy -> [124, 107, 44, 96, 114, 16, 47, 72, 13, 66, 37, 29, 8, 46, 31, 74, 60, 109, 101, 18, 97, 40, 50, 79, 10, 22, 110, 30, 56, 38]\n",
      "Train Epoch: 24 [0/437 (0%)]\tLoss: 0.457189\n",
      "SSIM: 0.45375582575798035\n",
      "PSNR: -72.95000457763672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [224/437 (50%)]\tLoss: 0.459524\n",
      "SSIM: 0.44868215918540955\n",
      "PSNR: -72.94486999511719\n",
      "Top 30 bands with Entropy -> [96, 107, 29, 124, 56, 8, 13, 47, 31, 11, 72, 44, 91, 16, 46, 114, 63, 74, 79, 40, 18, 50, 22, 10, 66, 60, 37, 101, 109, 20]\n",
      "Train Epoch: 25 [0/437 (0%)]\tLoss: 0.454875\n",
      "SSIM: 0.45326805114746094\n",
      "PSNR: -72.77217864990234\n",
      "Train Epoch: 25 [224/437 (50%)]\tLoss: 0.461843\n",
      "SSIM: 0.4581754207611084\n",
      "PSNR: -72.70948028564453\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 40, 22, 10, 50, 66, 60, 37, 101, 109, 20]\n",
      "Train Epoch: 26 [0/437 (0%)]\tLoss: 0.458621\n",
      "SSIM: 0.45686036348342896\n",
      "PSNR: -72.67546081542969\n",
      "Train Epoch: 26 [224/437 (50%)]\tLoss: 0.454545\n",
      "SSIM: 0.4535785913467407\n",
      "PSNR: -73.01214599609375\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 40, 50, 22, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 27 [0/437 (0%)]\tLoss: 0.454467\n",
      "SSIM: 0.43897733092308044\n",
      "PSNR: -73.12353515625\n",
      "Train Epoch: 27 [224/437 (50%)]\tLoss: 0.460330\n",
      "SSIM: 0.44324713945388794\n",
      "PSNR: -72.89826965332031\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 22, 40, 10, 50, 66, 60, 37, 109, 20, 101]\n",
      "Train Epoch: 28 [0/437 (0%)]\tLoss: 0.452921\n",
      "SSIM: 0.4543720781803131\n",
      "PSNR: -72.88645935058594\n",
      "Train Epoch: 28 [224/437 (50%)]\tLoss: 0.454561\n",
      "SSIM: 0.4497595727443695\n",
      "PSNR: -72.8297119140625\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 22, 40, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 29 [0/437 (0%)]\tLoss: 0.464061\n",
      "SSIM: 0.4490847587585449\n",
      "PSNR: -72.72467803955078\n",
      "Train Epoch: 29 [224/437 (50%)]\tLoss: 0.458345\n",
      "SSIM: 0.4535408020019531\n",
      "PSNR: -72.80036163330078\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 22, 40, 10, 50, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 30 [0/437 (0%)]\tLoss: 0.451672\n",
      "SSIM: 0.4461328089237213\n",
      "PSNR: -73.07797241210938\n",
      "Train Epoch: 30 [224/437 (50%)]\tLoss: 0.453981\n",
      "SSIM: 0.4573846757411957\n",
      "PSNR: -72.77139282226562\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 22, 40, 10, 50, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 31 [0/437 (0%)]\tLoss: 0.454888\n",
      "SSIM: 0.44696441292762756\n",
      "PSNR: -72.80297088623047\n",
      "Train Epoch: 31 [224/437 (50%)]\tLoss: 0.456013\n",
      "SSIM: 0.4581238925457001\n",
      "PSNR: -72.902587890625\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 40, 22, 10, 50, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 32 [0/437 (0%)]\tLoss: 0.465157\n",
      "SSIM: 0.45191970467567444\n",
      "PSNR: -72.47472381591797\n",
      "Train Epoch: 32 [224/437 (50%)]\tLoss: 0.453292\n",
      "SSIM: 0.45439469814300537\n",
      "PSNR: -72.89234924316406\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 22, 40, 10, 50, 66, 60, 37, 101, 109, 20]\n",
      "Train Epoch: 33 [0/437 (0%)]\tLoss: 0.460636\n",
      "SSIM: 0.4546237885951996\n",
      "PSNR: -72.6621322631836\n",
      "Train Epoch: 33 [224/437 (50%)]\tLoss: 0.458497\n",
      "SSIM: 0.4484202265739441\n",
      "PSNR: -72.95670318603516\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 22, 40, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 34 [0/437 (0%)]\tLoss: 0.452873\n",
      "SSIM: 0.45035046339035034\n",
      "PSNR: -72.89885711669922\n",
      "Train Epoch: 34 [224/437 (50%)]\tLoss: 0.453825\n",
      "SSIM: 0.45529529452323914\n",
      "PSNR: -73.00714111328125\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 22, 40, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 35 [0/437 (0%)]\tLoss: 0.460674\n",
      "SSIM: 0.4583047330379486\n",
      "PSNR: -72.64613342285156\n",
      "Train Epoch: 35 [224/437 (50%)]\tLoss: 0.454434\n",
      "SSIM: 0.454912006855011\n",
      "PSNR: -72.96856689453125\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 40, 10, 50, 22, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 36 [0/437 (0%)]\tLoss: 0.453139\n",
      "SSIM: 0.4439474642276764\n",
      "PSNR: -72.79900360107422\n",
      "Train Epoch: 36 [224/437 (50%)]\tLoss: 0.451461\n",
      "SSIM: 0.44652876257896423\n",
      "PSNR: -73.00285339355469\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 22, 40, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 37 [0/437 (0%)]\tLoss: 0.459554\n",
      "SSIM: 0.45621755719184875\n",
      "PSNR: -72.82069396972656\n",
      "Train Epoch: 37 [224/437 (50%)]\tLoss: 0.454806\n",
      "SSIM: 0.45268282294273376\n",
      "PSNR: -72.997802734375\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 22, 40, 10, 50, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 38 [0/437 (0%)]\tLoss: 0.452092\n",
      "SSIM: 0.4454723596572876\n",
      "PSNR: -72.78736114501953\n",
      "Train Epoch: 38 [224/437 (50%)]\tLoss: 0.458198\n",
      "SSIM: 0.45323020219802856\n",
      "PSNR: -72.7560806274414\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 22, 40, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 39 [0/437 (0%)]\tLoss: 0.455170\n",
      "SSIM: 0.44763004779815674\n",
      "PSNR: -72.99264526367188\n",
      "Train Epoch: 39 [224/437 (50%)]\tLoss: 0.456183\n",
      "SSIM: 0.4518360495567322\n",
      "PSNR: -72.8456802368164\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 40, 22, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 40 [0/437 (0%)]\tLoss: 0.454680\n",
      "SSIM: 0.4632803499698639\n",
      "PSNR: -72.73284149169922\n",
      "Train Epoch: 40 [224/437 (50%)]\tLoss: 0.452009\n",
      "SSIM: 0.4566448926925659\n",
      "PSNR: -72.98039245605469\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 40, 22, 10, 50, 66, 60, 37, 101, 109, 20]\n",
      "Train Epoch: 41 [0/437 (0%)]\tLoss: 0.460025\n",
      "SSIM: 0.45553502440452576\n",
      "PSNR: -72.80907440185547\n",
      "Train Epoch: 41 [224/437 (50%)]\tLoss: 0.461196\n",
      "SSIM: 0.4414122402667999\n",
      "PSNR: -72.92521667480469\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 22, 40, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 42 [0/437 (0%)]\tLoss: 0.461407\n",
      "SSIM: 0.4592379927635193\n",
      "PSNR: -72.62309265136719\n",
      "Train Epoch: 42 [224/437 (50%)]\tLoss: 0.457453\n",
      "SSIM: 0.45079636573791504\n",
      "PSNR: -73.00099182128906\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 22, 40, 10, 50, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 43 [0/437 (0%)]\tLoss: 0.457851\n",
      "SSIM: 0.44587862491607666\n",
      "PSNR: -72.72421264648438\n",
      "Train Epoch: 43 [224/437 (50%)]\tLoss: 0.454211\n",
      "SSIM: 0.4429851770401001\n",
      "PSNR: -73.07508087158203\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 40, 22, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 44 [0/437 (0%)]\tLoss: 0.455518\n",
      "SSIM: 0.45960190892219543\n",
      "PSNR: -72.8072280883789\n",
      "Train Epoch: 44 [224/437 (50%)]\tLoss: 0.455645\n",
      "SSIM: 0.4533552825450897\n",
      "PSNR: -72.92164611816406\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 40, 10, 50, 22, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 45 [0/437 (0%)]\tLoss: 0.455065\n",
      "SSIM: 0.443019300699234\n",
      "PSNR: -72.95892333984375\n",
      "Train Epoch: 45 [224/437 (50%)]\tLoss: 0.453694\n",
      "SSIM: 0.4561136066913605\n",
      "PSNR: -72.8878173828125\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 40, 50, 10, 22, 66, 60, 37, 20, 109, 101]\n",
      "Train Epoch: 46 [0/437 (0%)]\tLoss: 0.457082\n",
      "SSIM: 0.4517901837825775\n",
      "PSNR: -72.76416015625\n",
      "Train Epoch: 46 [224/437 (50%)]\tLoss: 0.457155\n",
      "SSIM: 0.4484502375125885\n",
      "PSNR: -72.95652770996094\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 40, 22, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 47 [0/437 (0%)]\tLoss: 0.464172\n",
      "SSIM: 0.46057718992233276\n",
      "PSNR: -72.55255889892578\n",
      "Train Epoch: 47 [224/437 (50%)]\tLoss: 0.464487\n",
      "SSIM: 0.45502158999443054\n",
      "PSNR: -72.49305725097656\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 22, 40, 10, 50, 66, 60, 37, 109, 20, 101]\n",
      "Train Epoch: 48 [0/437 (0%)]\tLoss: 0.457080\n",
      "SSIM: 0.4519340395927429\n",
      "PSNR: -72.97356414794922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [224/437 (50%)]\tLoss: 0.458018\n",
      "SSIM: 0.4449254274368286\n",
      "PSNR: -72.92639923095703\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 22, 40, 10, 50, 66, 60, 37, 101, 109, 20]\n",
      "Train Epoch: 49 [0/437 (0%)]\tLoss: 0.460796\n",
      "SSIM: 0.445035457611084\n",
      "PSNR: -72.86228942871094\n",
      "Train Epoch: 49 [224/437 (50%)]\tLoss: 0.455281\n",
      "SSIM: 0.45212599635124207\n",
      "PSNR: -72.74484252929688\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 63, 114, 16, 74, 79, 18, 40, 22, 50, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 50 [0/437 (0%)]\tLoss: 0.459949\n",
      "SSIM: 0.4517967402935028\n",
      "PSNR: -72.54889678955078\n",
      "Train Epoch: 50 [224/437 (50%)]\tLoss: 0.453180\n",
      "SSIM: 0.45773619413375854\n",
      "PSNR: -72.86860656738281\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 22, 40, 50, 10, 66, 60, 37, 20, 109, 101]\n",
      "Train Epoch: 51 [0/437 (0%)]\tLoss: 0.457104\n",
      "SSIM: 0.4452970027923584\n",
      "PSNR: -72.93942260742188\n",
      "Train Epoch: 51 [224/437 (50%)]\tLoss: 0.450749\n",
      "SSIM: 0.456549733877182\n",
      "PSNR: -72.92926025390625\n",
      "Top 30 bands with Entropy -> [96, 29, 107, 124, 56, 13, 8, 47, 91, 11, 31, 72, 44, 46, 114, 63, 16, 74, 79, 18, 40, 50, 22, 10, 66, 60, 37, 101, 20, 109]\n",
      "Train Epoch: 52 [0/437 (0%)]\tLoss: 0.451530\n",
      "SSIM: 0.44842299818992615\n",
      "PSNR: -73.0185546875\n",
      "Train Epoch: 52 [224/437 (50%)]\tLoss: 0.459757\n",
      "SSIM: 0.46321195363998413\n",
      "PSNR: -72.80351257324219\n",
      "Top 30 bands with Entropy -> [107, 29, 96, 91, 13, 63, 124, 16, 114, 74, 47, 50, 18, 40, 8, 46, 67, 44, 72, 38, 39, 31, 58, 11, 103, 79, 122, 56, 10, 42]\n",
      "Train Epoch: 53 [0/437 (0%)]\tLoss: 0.468570\n",
      "SSIM: 0.43755853176116943\n",
      "PSNR: -72.770263671875\n",
      "Train Epoch: 53 [224/437 (50%)]\tLoss: 0.474004\n",
      "SSIM: 0.442994087934494\n",
      "PSNR: -72.84241485595703\n",
      "Top 30 bands with Entropy -> [74, 58, 103, 39, 122, 91, 38, 67, 18, 63, 50, 114, 42, 16, 15, 89, 40, 107, 96, 13, 29, 47, 92, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 54 [0/437 (0%)]\tLoss: 0.475713\n",
      "SSIM: 0.45014727115631104\n",
      "PSNR: -72.52760314941406\n",
      "Train Epoch: 54 [224/437 (50%)]\tLoss: 0.474845\n",
      "SSIM: 0.44331854581832886\n",
      "PSNR: -72.68181610107422\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 55 [0/437 (0%)]\tLoss: 0.474425\n",
      "SSIM: 0.4532877802848816\n",
      "PSNR: -72.5783462524414\n",
      "Train Epoch: 55 [224/437 (50%)]\tLoss: 0.467995\n",
      "SSIM: 0.44806981086730957\n",
      "PSNR: -72.9306869506836\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 56 [0/437 (0%)]\tLoss: 0.471132\n",
      "SSIM: 0.45637714862823486\n",
      "PSNR: -72.71055603027344\n",
      "Train Epoch: 56 [224/437 (50%)]\tLoss: 0.471621\n",
      "SSIM: 0.4572734236717224\n",
      "PSNR: -72.7260971069336\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 57 [0/437 (0%)]\tLoss: 0.473778\n",
      "SSIM: 0.4602019786834717\n",
      "PSNR: -72.58757019042969\n",
      "Train Epoch: 57 [224/437 (50%)]\tLoss: 0.470190\n",
      "SSIM: 0.4453572928905487\n",
      "PSNR: -72.83515167236328\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 58 [0/437 (0%)]\tLoss: 0.471881\n",
      "SSIM: 0.44336217641830444\n",
      "PSNR: -72.78692626953125\n",
      "Train Epoch: 58 [224/437 (50%)]\tLoss: 0.472446\n",
      "SSIM: 0.4569384455680847\n",
      "PSNR: -72.61461639404297\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 59 [0/437 (0%)]\tLoss: 0.479048\n",
      "SSIM: 0.44054940342903137\n",
      "PSNR: -72.5576400756836\n",
      "Train Epoch: 59 [224/437 (50%)]\tLoss: 0.470452\n",
      "SSIM: 0.45617184042930603\n",
      "PSNR: -72.59514617919922\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 60 [0/437 (0%)]\tLoss: 0.470477\n",
      "SSIM: 0.45478928089141846\n",
      "PSNR: -72.7429428100586\n",
      "Train Epoch: 60 [224/437 (50%)]\tLoss: 0.465938\n",
      "SSIM: 0.4535399377346039\n",
      "PSNR: -72.77574157714844\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 61 [0/437 (0%)]\tLoss: 0.469607\n",
      "SSIM: 0.4465768039226532\n",
      "PSNR: -72.85499572753906\n",
      "Train Epoch: 61 [224/437 (50%)]\tLoss: 0.474587\n",
      "SSIM: 0.4528919756412506\n",
      "PSNR: -72.6367416381836\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 62 [0/437 (0%)]\tLoss: 0.470778\n",
      "SSIM: 0.4492754638195038\n",
      "PSNR: -72.81103515625\n",
      "Train Epoch: 62 [224/437 (50%)]\tLoss: 0.474147\n",
      "SSIM: 0.44965144991874695\n",
      "PSNR: -72.62029266357422\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 63 [0/437 (0%)]\tLoss: 0.467711\n",
      "SSIM: 0.45600250363349915\n",
      "PSNR: -72.78741455078125\n",
      "Train Epoch: 63 [224/437 (50%)]\tLoss: 0.469615\n",
      "SSIM: 0.46316978335380554\n",
      "PSNR: -72.57672119140625\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 47, 29, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 64 [0/437 (0%)]\tLoss: 0.468489\n",
      "SSIM: 0.46384188532829285\n",
      "PSNR: -72.6316909790039\n",
      "Train Epoch: 64 [224/437 (50%)]\tLoss: 0.474957\n",
      "SSIM: 0.45133793354034424\n",
      "PSNR: -72.61273193359375\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 65 [0/437 (0%)]\tLoss: 0.469593\n",
      "SSIM: 0.4520326256752014\n",
      "PSNR: -72.7026596069336\n",
      "Train Epoch: 65 [224/437 (50%)]\tLoss: 0.473217\n",
      "SSIM: 0.45423370599746704\n",
      "PSNR: -72.69889831542969\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 66 [0/437 (0%)]\tLoss: 0.480404\n",
      "SSIM: 0.4578065276145935\n",
      "PSNR: -72.33296203613281\n",
      "Train Epoch: 66 [224/437 (50%)]\tLoss: 0.471404\n",
      "SSIM: 0.4610724449157715\n",
      "PSNR: -72.55327606201172\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 67 [0/437 (0%)]\tLoss: 0.475322\n",
      "SSIM: 0.45464760065078735\n",
      "PSNR: -72.54039764404297\n",
      "Train Epoch: 67 [224/437 (50%)]\tLoss: 0.473589\n",
      "SSIM: 0.4584268033504486\n",
      "PSNR: -72.53653717041016\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 68 [0/437 (0%)]\tLoss: 0.473961\n",
      "SSIM: 0.45084837079048157\n",
      "PSNR: -72.81632995605469\n",
      "Train Epoch: 68 [224/437 (50%)]\tLoss: 0.469079\n",
      "SSIM: 0.4451194107532501\n",
      "PSNR: -72.85099792480469\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 69 [0/437 (0%)]\tLoss: 0.473357\n",
      "SSIM: 0.4614507555961609\n",
      "PSNR: -72.53805541992188\n",
      "Train Epoch: 69 [224/437 (50%)]\tLoss: 0.474509\n",
      "SSIM: 0.4493134915828705\n",
      "PSNR: -72.60472869873047\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 70 [0/437 (0%)]\tLoss: 0.480305\n",
      "SSIM: 0.446234792470932\n",
      "PSNR: -72.68354797363281\n",
      "Train Epoch: 70 [224/437 (50%)]\tLoss: 0.465204\n",
      "SSIM: 0.4463009238243103\n",
      "PSNR: -72.76483154296875\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 10]\n",
      "Train Epoch: 71 [0/437 (0%)]\tLoss: 0.466841\n",
      "SSIM: 0.45952320098876953\n",
      "PSNR: -72.56661987304688\n",
      "Train Epoch: 71 [224/437 (50%)]\tLoss: 0.468781\n",
      "SSIM: 0.4607030153274536\n",
      "PSNR: -72.66912078857422\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 72 [0/437 (0%)]\tLoss: 0.467533\n",
      "SSIM: 0.45649412274360657\n",
      "PSNR: -72.64476013183594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72 [224/437 (50%)]\tLoss: 0.477673\n",
      "SSIM: 0.45427095890045166\n",
      "PSNR: -72.5452880859375\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 73 [0/437 (0%)]\tLoss: 0.478978\n",
      "SSIM: 0.4394676685333252\n",
      "PSNR: -72.75007629394531\n",
      "Train Epoch: 73 [224/437 (50%)]\tLoss: 0.468172\n",
      "SSIM: 0.44046759605407715\n",
      "PSNR: -72.84100341796875\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 74 [0/437 (0%)]\tLoss: 0.470627\n",
      "SSIM: 0.45930784940719604\n",
      "PSNR: -72.68887329101562\n",
      "Train Epoch: 74 [224/437 (50%)]\tLoss: 0.469363\n",
      "SSIM: 0.44950273633003235\n",
      "PSNR: -72.66265869140625\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 75 [0/437 (0%)]\tLoss: 0.471879\n",
      "SSIM: 0.4610016644001007\n",
      "PSNR: -72.68319702148438\n",
      "Train Epoch: 75 [224/437 (50%)]\tLoss: 0.475782\n",
      "SSIM: 0.4467942714691162\n",
      "PSNR: -72.69517517089844\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 76 [0/437 (0%)]\tLoss: 0.472330\n",
      "SSIM: 0.45728278160095215\n",
      "PSNR: -72.57821655273438\n",
      "Train Epoch: 76 [224/437 (50%)]\tLoss: 0.473395\n",
      "SSIM: 0.45619410276412964\n",
      "PSNR: -72.55916595458984\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 77 [0/437 (0%)]\tLoss: 0.471809\n",
      "SSIM: 0.4555804431438446\n",
      "PSNR: -72.69143676757812\n",
      "Train Epoch: 77 [224/437 (50%)]\tLoss: 0.479271\n",
      "SSIM: 0.4496030807495117\n",
      "PSNR: -72.70729064941406\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 78 [0/437 (0%)]\tLoss: 0.471217\n",
      "SSIM: 0.4591488540172577\n",
      "PSNR: -72.5595932006836\n",
      "Train Epoch: 78 [224/437 (50%)]\tLoss: 0.468383\n",
      "SSIM: 0.45278263092041016\n",
      "PSNR: -72.80235290527344\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 79 [0/437 (0%)]\tLoss: 0.468738\n",
      "SSIM: 0.4523701071739197\n",
      "PSNR: -72.60749816894531\n",
      "Train Epoch: 79 [224/437 (50%)]\tLoss: 0.473566\n",
      "SSIM: 0.45170554518699646\n",
      "PSNR: -72.76361846923828\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 80 [0/437 (0%)]\tLoss: 0.469216\n",
      "SSIM: 0.44614654779434204\n",
      "PSNR: -72.79772186279297\n",
      "Train Epoch: 80 [224/437 (50%)]\tLoss: 0.471366\n",
      "SSIM: 0.45847564935684204\n",
      "PSNR: -72.49634552001953\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 81 [0/437 (0%)]\tLoss: 0.466406\n",
      "SSIM: 0.45876216888427734\n",
      "PSNR: -72.818359375\n",
      "Train Epoch: 81 [224/437 (50%)]\tLoss: 0.468293\n",
      "SSIM: 0.4467916488647461\n",
      "PSNR: -72.99856567382812\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 82 [0/437 (0%)]\tLoss: 0.479020\n",
      "SSIM: 0.44369739294052124\n",
      "PSNR: -72.63701629638672\n",
      "Train Epoch: 82 [224/437 (50%)]\tLoss: 0.467589\n",
      "SSIM: 0.463050901889801\n",
      "PSNR: -72.5028076171875\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 83 [0/437 (0%)]\tLoss: 0.471057\n",
      "SSIM: 0.44996821880340576\n",
      "PSNR: -72.76457214355469\n",
      "Train Epoch: 83 [224/437 (50%)]\tLoss: 0.471077\n",
      "SSIM: 0.45397987961769104\n",
      "PSNR: -72.64348602294922\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 84 [0/437 (0%)]\tLoss: 0.467893\n",
      "SSIM: 0.44659602642059326\n",
      "PSNR: -73.01886749267578\n",
      "Train Epoch: 84 [224/437 (50%)]\tLoss: 0.463253\n",
      "SSIM: 0.44851458072662354\n",
      "PSNR: -72.95930480957031\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 85 [0/437 (0%)]\tLoss: 0.480038\n",
      "SSIM: 0.45042115449905396\n",
      "PSNR: -72.59211730957031\n",
      "Train Epoch: 85 [224/437 (50%)]\tLoss: 0.476199\n",
      "SSIM: 0.44747307896614075\n",
      "PSNR: -72.68001556396484\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 86 [0/437 (0%)]\tLoss: 0.472295\n",
      "SSIM: 0.4405311644077301\n",
      "PSNR: -72.75936126708984\n",
      "Train Epoch: 86 [224/437 (50%)]\tLoss: 0.464358\n",
      "SSIM: 0.44427669048309326\n",
      "PSNR: -72.93193054199219\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 87 [0/437 (0%)]\tLoss: 0.475805\n",
      "SSIM: 0.44797590374946594\n",
      "PSNR: -72.58362579345703\n",
      "Train Epoch: 87 [224/437 (50%)]\tLoss: 0.466981\n",
      "SSIM: 0.454405277967453\n",
      "PSNR: -72.7159652709961\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 88 [0/437 (0%)]\tLoss: 0.468678\n",
      "SSIM: 0.4571574628353119\n",
      "PSNR: -72.74305725097656\n",
      "Train Epoch: 88 [224/437 (50%)]\tLoss: 0.469489\n",
      "SSIM: 0.4603002071380615\n",
      "PSNR: -72.65765380859375\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 47, 29, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 89 [0/437 (0%)]\tLoss: 0.480042\n",
      "SSIM: 0.447462260723114\n",
      "PSNR: -72.47869873046875\n",
      "Train Epoch: 89 [224/437 (50%)]\tLoss: 0.478048\n",
      "SSIM: 0.453559547662735\n",
      "PSNR: -72.53495025634766\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 90 [0/437 (0%)]\tLoss: 0.476727\n",
      "SSIM: 0.45248648524284363\n",
      "PSNR: -72.52629089355469\n",
      "Train Epoch: 90 [224/437 (50%)]\tLoss: 0.469214\n",
      "SSIM: 0.45083382725715637\n",
      "PSNR: -72.67935180664062\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 91 [0/437 (0%)]\tLoss: 0.473334\n",
      "SSIM: 0.4529207944869995\n",
      "PSNR: -72.7217025756836\n",
      "Train Epoch: 91 [224/437 (50%)]\tLoss: 0.471769\n",
      "SSIM: 0.4524354636669159\n",
      "PSNR: -72.55438995361328\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 47, 29, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 92 [0/437 (0%)]\tLoss: 0.468968\n",
      "SSIM: 0.44461536407470703\n",
      "PSNR: -72.80381774902344\n",
      "Train Epoch: 92 [224/437 (50%)]\tLoss: 0.475010\n",
      "SSIM: 0.4449559450149536\n",
      "PSNR: -72.77665710449219\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 93 [0/437 (0%)]\tLoss: 0.461003\n",
      "SSIM: 0.4523218870162964\n",
      "PSNR: -72.7435302734375\n",
      "Train Epoch: 93 [224/437 (50%)]\tLoss: 0.469806\n",
      "SSIM: 0.4504246413707733\n",
      "PSNR: -72.7265625\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 79]\n",
      "Train Epoch: 94 [0/437 (0%)]\tLoss: 0.470240\n",
      "SSIM: 0.45737940073013306\n",
      "PSNR: -72.57276916503906\n",
      "Train Epoch: 94 [224/437 (50%)]\tLoss: 0.465801\n",
      "SSIM: 0.45676106214523315\n",
      "PSNR: -72.77391052246094\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 95 [0/437 (0%)]\tLoss: 0.475512\n",
      "SSIM: 0.4541439712047577\n",
      "PSNR: -72.45394897460938\n",
      "Train Epoch: 95 [224/437 (50%)]\tLoss: 0.476904\n",
      "SSIM: 0.45188382267951965\n",
      "PSNR: -72.53934478759766\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 96 [0/437 (0%)]\tLoss: 0.470830\n",
      "SSIM: 0.4515208303928375\n",
      "PSNR: -72.60852813720703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 96 [224/437 (50%)]\tLoss: 0.472225\n",
      "SSIM: 0.4481823146343231\n",
      "PSNR: -72.78828430175781\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 97 [0/437 (0%)]\tLoss: 0.470954\n",
      "SSIM: 0.4534280300140381\n",
      "PSNR: -72.66026306152344\n",
      "Train Epoch: 97 [224/437 (50%)]\tLoss: 0.474132\n",
      "SSIM: 0.44344502687454224\n",
      "PSNR: -72.69552612304688\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 98 [0/437 (0%)]\tLoss: 0.467549\n",
      "SSIM: 0.45144519209861755\n",
      "PSNR: -72.77809143066406\n",
      "Train Epoch: 98 [224/437 (50%)]\tLoss: 0.474493\n",
      "SSIM: 0.4478064477443695\n",
      "PSNR: -72.7428207397461\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 99 [0/437 (0%)]\tLoss: 0.469182\n",
      "SSIM: 0.4515909254550934\n",
      "PSNR: -72.73094177246094\n",
      "Train Epoch: 99 [224/437 (50%)]\tLoss: 0.470954\n",
      "SSIM: 0.4492289125919342\n",
      "PSNR: -72.82443237304688\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 100 [0/437 (0%)]\tLoss: 0.470446\n",
      "SSIM: 0.4421446621417999\n",
      "PSNR: -72.90910339355469\n",
      "Train Epoch: 100 [224/437 (50%)]\tLoss: 0.471679\n",
      "SSIM: 0.4553251266479492\n",
      "PSNR: -72.63751220703125\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 101 [0/437 (0%)]\tLoss: 0.469700\n",
      "SSIM: 0.45856061577796936\n",
      "PSNR: -72.77240753173828\n",
      "Train Epoch: 101 [224/437 (50%)]\tLoss: 0.473091\n",
      "SSIM: 0.44266414642333984\n",
      "PSNR: -72.47361755371094\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 102 [0/437 (0%)]\tLoss: 0.475189\n",
      "SSIM: 0.45260682702064514\n",
      "PSNR: -72.7166519165039\n",
      "Train Epoch: 102 [224/437 (50%)]\tLoss: 0.462072\n",
      "SSIM: 0.46363502740859985\n",
      "PSNR: -72.86338806152344\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 103 [0/437 (0%)]\tLoss: 0.472765\n",
      "SSIM: 0.45730215311050415\n",
      "PSNR: -72.68224334716797\n",
      "Train Epoch: 103 [224/437 (50%)]\tLoss: 0.475762\n",
      "SSIM: 0.46098294854164124\n",
      "PSNR: -72.44371795654297\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 104 [0/437 (0%)]\tLoss: 0.474991\n",
      "SSIM: 0.4458964467048645\n",
      "PSNR: -72.70835876464844\n",
      "Train Epoch: 104 [224/437 (50%)]\tLoss: 0.473534\n",
      "SSIM: 0.45168668031692505\n",
      "PSNR: -72.67974853515625\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 105 [0/437 (0%)]\tLoss: 0.473959\n",
      "SSIM: 0.4507279694080353\n",
      "PSNR: -72.73339080810547\n",
      "Train Epoch: 105 [224/437 (50%)]\tLoss: 0.474183\n",
      "SSIM: 0.454763799905777\n",
      "PSNR: -72.58971405029297\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 47, 29, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 106 [0/437 (0%)]\tLoss: 0.466134\n",
      "SSIM: 0.45093244314193726\n",
      "PSNR: -72.90020751953125\n",
      "Train Epoch: 106 [224/437 (50%)]\tLoss: 0.474755\n",
      "SSIM: 0.45526427030563354\n",
      "PSNR: -72.55915832519531\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 107 [0/437 (0%)]\tLoss: 0.466928\n",
      "SSIM: 0.4425060451030731\n",
      "PSNR: -72.97647857666016\n",
      "Train Epoch: 107 [224/437 (50%)]\tLoss: 0.468187\n",
      "SSIM: 0.45079827308654785\n",
      "PSNR: -72.76713562011719\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 108 [0/437 (0%)]\tLoss: 0.470690\n",
      "SSIM: 0.4550274610519409\n",
      "PSNR: -72.66307067871094\n",
      "Train Epoch: 108 [224/437 (50%)]\tLoss: 0.473395\n",
      "SSIM: 0.4462413191795349\n",
      "PSNR: -72.73672485351562\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 109 [0/437 (0%)]\tLoss: 0.473552\n",
      "SSIM: 0.459227055311203\n",
      "PSNR: -72.5819320678711\n",
      "Train Epoch: 109 [224/437 (50%)]\tLoss: 0.477943\n",
      "SSIM: 0.4558395445346832\n",
      "PSNR: -72.33307647705078\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 110 [0/437 (0%)]\tLoss: 0.472650\n",
      "SSIM: 0.4494797885417938\n",
      "PSNR: -72.54672241210938\n",
      "Train Epoch: 110 [224/437 (50%)]\tLoss: 0.473175\n",
      "SSIM: 0.45965975522994995\n",
      "PSNR: -72.61837005615234\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 111 [0/437 (0%)]\tLoss: 0.479849\n",
      "SSIM: 0.45145952701568604\n",
      "PSNR: -72.4818115234375\n",
      "Train Epoch: 111 [224/437 (50%)]\tLoss: 0.466577\n",
      "SSIM: 0.46404701471328735\n",
      "PSNR: -72.65040588378906\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 112 [0/437 (0%)]\tLoss: 0.475057\n",
      "SSIM: 0.4484961926937103\n",
      "PSNR: -72.64579010009766\n",
      "Train Epoch: 112 [224/437 (50%)]\tLoss: 0.463836\n",
      "SSIM: 0.46368592977523804\n",
      "PSNR: -72.7101821899414\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 113 [0/437 (0%)]\tLoss: 0.468956\n",
      "SSIM: 0.45691242814064026\n",
      "PSNR: -72.696533203125\n",
      "Train Epoch: 113 [224/437 (50%)]\tLoss: 0.474822\n",
      "SSIM: 0.45136362314224243\n",
      "PSNR: -72.54472351074219\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 114 [0/437 (0%)]\tLoss: 0.474874\n",
      "SSIM: 0.45114073157310486\n",
      "PSNR: -72.74922180175781\n",
      "Train Epoch: 114 [224/437 (50%)]\tLoss: 0.468474\n",
      "SSIM: 0.4531441926956177\n",
      "PSNR: -72.62512969970703\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 115 [0/437 (0%)]\tLoss: 0.473898\n",
      "SSIM: 0.45860472321510315\n",
      "PSNR: -72.64584350585938\n",
      "Train Epoch: 115 [224/437 (50%)]\tLoss: 0.474557\n",
      "SSIM: 0.4503616392612457\n",
      "PSNR: -72.74560546875\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 92, 47, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 116 [0/437 (0%)]\tLoss: 0.474936\n",
      "SSIM: 0.4521404504776001\n",
      "PSNR: -72.55476379394531\n",
      "Train Epoch: 116 [224/437 (50%)]\tLoss: 0.478266\n",
      "SSIM: 0.4403741657733917\n",
      "PSNR: -72.74761962890625\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 117 [0/437 (0%)]\tLoss: 0.463476\n",
      "SSIM: 0.457972913980484\n",
      "PSNR: -72.86071014404297\n",
      "Train Epoch: 117 [224/437 (50%)]\tLoss: 0.467775\n",
      "SSIM: 0.4467542767524719\n",
      "PSNR: -72.6355209350586\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 118 [0/437 (0%)]\tLoss: 0.481113\n",
      "SSIM: 0.4527299702167511\n",
      "PSNR: -72.2709732055664\n",
      "Train Epoch: 118 [224/437 (50%)]\tLoss: 0.474780\n",
      "SSIM: 0.4553404450416565\n",
      "PSNR: -72.4945068359375\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 119 [0/437 (0%)]\tLoss: 0.483514\n",
      "SSIM: 0.4524913728237152\n",
      "PSNR: -72.56204223632812\n",
      "Train Epoch: 119 [224/437 (50%)]\tLoss: 0.474723\n",
      "SSIM: 0.44634321331977844\n",
      "PSNR: -72.70584869384766\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 120 [0/437 (0%)]\tLoss: 0.471400\n",
      "SSIM: 0.446759432554245\n",
      "PSNR: -72.82292938232422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 120 [224/437 (50%)]\tLoss: 0.470143\n",
      "SSIM: 0.44789600372314453\n",
      "PSNR: -72.80171203613281\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 121 [0/437 (0%)]\tLoss: 0.469098\n",
      "SSIM: 0.45241421461105347\n",
      "PSNR: -72.81670379638672\n",
      "Train Epoch: 121 [224/437 (50%)]\tLoss: 0.478194\n",
      "SSIM: 0.4625205993652344\n",
      "PSNR: -72.46515655517578\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 122 [0/437 (0%)]\tLoss: 0.472130\n",
      "SSIM: 0.457838237285614\n",
      "PSNR: -72.59209442138672\n",
      "Train Epoch: 122 [224/437 (50%)]\tLoss: 0.473362\n",
      "SSIM: 0.456344336271286\n",
      "PSNR: -72.70277404785156\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 123 [0/437 (0%)]\tLoss: 0.465084\n",
      "SSIM: 0.4559556841850281\n",
      "PSNR: -72.77740478515625\n",
      "Train Epoch: 123 [224/437 (50%)]\tLoss: 0.468189\n",
      "SSIM: 0.45662689208984375\n",
      "PSNR: -72.75153350830078\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 124 [0/437 (0%)]\tLoss: 0.469108\n",
      "SSIM: 0.4501362442970276\n",
      "PSNR: -72.8431625366211\n",
      "Train Epoch: 124 [224/437 (50%)]\tLoss: 0.470137\n",
      "SSIM: 0.45058226585388184\n",
      "PSNR: -72.68244171142578\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 125 [0/437 (0%)]\tLoss: 0.471530\n",
      "SSIM: 0.45546239614486694\n",
      "PSNR: -72.71513366699219\n",
      "Train Epoch: 125 [224/437 (50%)]\tLoss: 0.473171\n",
      "SSIM: 0.4496096670627594\n",
      "PSNR: -72.76399230957031\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 126 [0/437 (0%)]\tLoss: 0.480241\n",
      "SSIM: 0.45732972025871277\n",
      "PSNR: -72.44568634033203\n",
      "Train Epoch: 126 [224/437 (50%)]\tLoss: 0.474775\n",
      "SSIM: 0.4573083519935608\n",
      "PSNR: -72.53942108154297\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 127 [0/437 (0%)]\tLoss: 0.464741\n",
      "SSIM: 0.45122238993644714\n",
      "PSNR: -72.8358154296875\n",
      "Train Epoch: 127 [224/437 (50%)]\tLoss: 0.473871\n",
      "SSIM: 0.45190078020095825\n",
      "PSNR: -72.68600463867188\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 128 [0/437 (0%)]\tLoss: 0.471728\n",
      "SSIM: 0.4478231966495514\n",
      "PSNR: -72.7072982788086\n",
      "Train Epoch: 128 [224/437 (50%)]\tLoss: 0.469085\n",
      "SSIM: 0.4558558166027069\n",
      "PSNR: -72.75116729736328\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 129 [0/437 (0%)]\tLoss: 0.471818\n",
      "SSIM: 0.4462411105632782\n",
      "PSNR: -72.56867218017578\n",
      "Train Epoch: 129 [224/437 (50%)]\tLoss: 0.478960\n",
      "SSIM: 0.4473700523376465\n",
      "PSNR: -72.52778625488281\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 130 [0/437 (0%)]\tLoss: 0.474579\n",
      "SSIM: 0.44952306151390076\n",
      "PSNR: -72.58985137939453\n",
      "Train Epoch: 130 [224/437 (50%)]\tLoss: 0.467740\n",
      "SSIM: 0.4523010849952698\n",
      "PSNR: -72.72401428222656\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 131 [0/437 (0%)]\tLoss: 0.480416\n",
      "SSIM: 0.4543721675872803\n",
      "PSNR: -72.41162109375\n",
      "Train Epoch: 131 [224/437 (50%)]\tLoss: 0.473265\n",
      "SSIM: 0.45426294207572937\n",
      "PSNR: -72.68731689453125\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 132 [0/437 (0%)]\tLoss: 0.474933\n",
      "SSIM: 0.4548947513103485\n",
      "PSNR: -72.40631103515625\n",
      "Train Epoch: 132 [224/437 (50%)]\tLoss: 0.476139\n",
      "SSIM: 0.45662984251976013\n",
      "PSNR: -72.60989379882812\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 133 [0/437 (0%)]\tLoss: 0.478134\n",
      "SSIM: 0.4462369978427887\n",
      "PSNR: -72.6908950805664\n",
      "Train Epoch: 133 [224/437 (50%)]\tLoss: 0.468170\n",
      "SSIM: 0.4524996280670166\n",
      "PSNR: -72.72564697265625\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 134 [0/437 (0%)]\tLoss: 0.470939\n",
      "SSIM: 0.45140019059181213\n",
      "PSNR: -72.64128112792969\n",
      "Train Epoch: 134 [224/437 (50%)]\tLoss: 0.476460\n",
      "SSIM: 0.4487206041812897\n",
      "PSNR: -72.6462173461914\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 79]\n",
      "Train Epoch: 135 [0/437 (0%)]\tLoss: 0.470767\n",
      "SSIM: 0.4457983672618866\n",
      "PSNR: -72.70608520507812\n",
      "Train Epoch: 135 [224/437 (50%)]\tLoss: 0.472296\n",
      "SSIM: 0.4488075375556946\n",
      "PSNR: -72.70550537109375\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 136 [0/437 (0%)]\tLoss: 0.474359\n",
      "SSIM: 0.45797720551490784\n",
      "PSNR: -72.4818344116211\n",
      "Train Epoch: 136 [224/437 (50%)]\tLoss: 0.469768\n",
      "SSIM: 0.4512597918510437\n",
      "PSNR: -72.79954528808594\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 137 [0/437 (0%)]\tLoss: 0.470404\n",
      "SSIM: 0.44843408465385437\n",
      "PSNR: -72.64341735839844\n",
      "Train Epoch: 137 [224/437 (50%)]\tLoss: 0.474982\n",
      "SSIM: 0.44933784008026123\n",
      "PSNR: -72.62537384033203\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 138 [0/437 (0%)]\tLoss: 0.474023\n",
      "SSIM: 0.45264947414398193\n",
      "PSNR: -72.53982543945312\n",
      "Train Epoch: 138 [224/437 (50%)]\tLoss: 0.473767\n",
      "SSIM: 0.44654807448387146\n",
      "PSNR: -72.73941802978516\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 139 [0/437 (0%)]\tLoss: 0.476629\n",
      "SSIM: 0.45908960700035095\n",
      "PSNR: -72.47168731689453\n",
      "Train Epoch: 139 [224/437 (50%)]\tLoss: 0.472188\n",
      "SSIM: 0.4587237238883972\n",
      "PSNR: -72.50714111328125\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 140 [0/437 (0%)]\tLoss: 0.470941\n",
      "SSIM: 0.45431751012802124\n",
      "PSNR: -72.82649230957031\n",
      "Train Epoch: 140 [224/437 (50%)]\tLoss: 0.472982\n",
      "SSIM: 0.4461062550544739\n",
      "PSNR: -72.76919555664062\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 141 [0/437 (0%)]\tLoss: 0.467386\n",
      "SSIM: 0.4476306736469269\n",
      "PSNR: -72.84424591064453\n",
      "Train Epoch: 141 [224/437 (50%)]\tLoss: 0.469623\n",
      "SSIM: 0.4461137056350708\n",
      "PSNR: -72.82771301269531\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 142 [0/437 (0%)]\tLoss: 0.465411\n",
      "SSIM: 0.4583274722099304\n",
      "PSNR: -72.81214141845703\n",
      "Train Epoch: 142 [224/437 (50%)]\tLoss: 0.469581\n",
      "SSIM: 0.463295042514801\n",
      "PSNR: -72.51513671875\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 143 [0/437 (0%)]\tLoss: 0.476895\n",
      "SSIM: 0.44727012515068054\n",
      "PSNR: -72.7506332397461\n",
      "Train Epoch: 143 [224/437 (50%)]\tLoss: 0.470479\n",
      "SSIM: 0.45429691672325134\n",
      "PSNR: -72.67251586914062\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 144 [0/437 (0%)]\tLoss: 0.470838\n",
      "SSIM: 0.45544859766960144\n",
      "PSNR: -72.68146514892578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 144 [224/437 (50%)]\tLoss: 0.468739\n",
      "SSIM: 0.4579561948776245\n",
      "PSNR: -72.6301040649414\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 145 [0/437 (0%)]\tLoss: 0.478174\n",
      "SSIM: 0.44647207856178284\n",
      "PSNR: -72.67943572998047\n",
      "Train Epoch: 145 [224/437 (50%)]\tLoss: 0.471928\n",
      "SSIM: 0.4529992341995239\n",
      "PSNR: -72.61917877197266\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 146 [0/437 (0%)]\tLoss: 0.470563\n",
      "SSIM: 0.46107661724090576\n",
      "PSNR: -72.65652465820312\n",
      "Train Epoch: 146 [224/437 (50%)]\tLoss: 0.474792\n",
      "SSIM: 0.44306984543800354\n",
      "PSNR: -72.6999282836914\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 147 [0/437 (0%)]\tLoss: 0.471672\n",
      "SSIM: 0.4502768814563751\n",
      "PSNR: -72.70669555664062\n",
      "Train Epoch: 147 [224/437 (50%)]\tLoss: 0.473723\n",
      "SSIM: 0.45095086097717285\n",
      "PSNR: -72.65221405029297\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 148 [0/437 (0%)]\tLoss: 0.462672\n",
      "SSIM: 0.45827195048332214\n",
      "PSNR: -72.81839752197266\n",
      "Train Epoch: 148 [224/437 (50%)]\tLoss: 0.473495\n",
      "SSIM: 0.43986785411834717\n",
      "PSNR: -72.76187896728516\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 79]\n",
      "Train Epoch: 149 [0/437 (0%)]\tLoss: 0.472248\n",
      "SSIM: 0.4476231038570404\n",
      "PSNR: -72.73348999023438\n",
      "Train Epoch: 149 [224/437 (50%)]\tLoss: 0.478029\n",
      "SSIM: 0.44586023688316345\n",
      "PSNR: -72.6363525390625\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 150 [0/437 (0%)]\tLoss: 0.478087\n",
      "SSIM: 0.4603627920150757\n",
      "PSNR: -72.46867370605469\n",
      "Train Epoch: 150 [224/437 (50%)]\tLoss: 0.473529\n",
      "SSIM: 0.4575611650943756\n",
      "PSNR: -72.64559936523438\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 151 [0/437 (0%)]\tLoss: 0.477214\n",
      "SSIM: 0.45288294553756714\n",
      "PSNR: -72.49337005615234\n",
      "Train Epoch: 151 [224/437 (50%)]\tLoss: 0.471631\n",
      "SSIM: 0.4616231620311737\n",
      "PSNR: -72.51689147949219\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 152 [0/437 (0%)]\tLoss: 0.477570\n",
      "SSIM: 0.4499756097793579\n",
      "PSNR: -72.57071685791016\n",
      "Train Epoch: 152 [224/437 (50%)]\tLoss: 0.469473\n",
      "SSIM: 0.45285236835479736\n",
      "PSNR: -72.67637634277344\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 153 [0/437 (0%)]\tLoss: 0.473046\n",
      "SSIM: 0.4514055848121643\n",
      "PSNR: -72.74459838867188\n",
      "Train Epoch: 153 [224/437 (50%)]\tLoss: 0.480819\n",
      "SSIM: 0.44950708746910095\n",
      "PSNR: -72.63409423828125\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 154 [0/437 (0%)]\tLoss: 0.481899\n",
      "SSIM: 0.46174177527427673\n",
      "PSNR: -72.34014892578125\n",
      "Train Epoch: 154 [224/437 (50%)]\tLoss: 0.474511\n",
      "SSIM: 0.44892844557762146\n",
      "PSNR: -72.655029296875\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 155 [0/437 (0%)]\tLoss: 0.476287\n",
      "SSIM: 0.45479467511177063\n",
      "PSNR: -72.50020599365234\n",
      "Train Epoch: 155 [224/437 (50%)]\tLoss: 0.472038\n",
      "SSIM: 0.45145708322525024\n",
      "PSNR: -72.76822662353516\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 92, 47, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 156 [0/437 (0%)]\tLoss: 0.473681\n",
      "SSIM: 0.44523417949676514\n",
      "PSNR: -72.49615478515625\n",
      "Train Epoch: 156 [224/437 (50%)]\tLoss: 0.469780\n",
      "SSIM: 0.4562881886959076\n",
      "PSNR: -72.54590606689453\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 157 [0/437 (0%)]\tLoss: 0.473657\n",
      "SSIM: 0.4504459798336029\n",
      "PSNR: -72.70568084716797\n",
      "Train Epoch: 157 [224/437 (50%)]\tLoss: 0.473471\n",
      "SSIM: 0.45312604308128357\n",
      "PSNR: -72.53312683105469\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 158 [0/437 (0%)]\tLoss: 0.471160\n",
      "SSIM: 0.45620134472846985\n",
      "PSNR: -72.68588256835938\n",
      "Train Epoch: 158 [224/437 (50%)]\tLoss: 0.479622\n",
      "SSIM: 0.4581551253795624\n",
      "PSNR: -72.46166229248047\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 159 [0/437 (0%)]\tLoss: 0.471501\n",
      "SSIM: 0.4580698609352112\n",
      "PSNR: -72.56348419189453\n",
      "Train Epoch: 159 [224/437 (50%)]\tLoss: 0.472703\n",
      "SSIM: 0.4473342299461365\n",
      "PSNR: -72.63203430175781\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 160 [0/437 (0%)]\tLoss: 0.470922\n",
      "SSIM: 0.4558444321155548\n",
      "PSNR: -72.68900299072266\n",
      "Train Epoch: 160 [224/437 (50%)]\tLoss: 0.469804\n",
      "SSIM: 0.45245951414108276\n",
      "PSNR: -72.70475769042969\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 161 [0/437 (0%)]\tLoss: 0.467426\n",
      "SSIM: 0.4576916992664337\n",
      "PSNR: -72.65282440185547\n",
      "Train Epoch: 161 [224/437 (50%)]\tLoss: 0.466781\n",
      "SSIM: 0.45914795994758606\n",
      "PSNR: -72.63243865966797\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 162 [0/437 (0%)]\tLoss: 0.467447\n",
      "SSIM: 0.450747549533844\n",
      "PSNR: -72.83624267578125\n",
      "Train Epoch: 162 [224/437 (50%)]\tLoss: 0.466409\n",
      "SSIM: 0.4494754672050476\n",
      "PSNR: -72.8199462890625\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 47, 29, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 163 [0/437 (0%)]\tLoss: 0.467673\n",
      "SSIM: 0.4487031400203705\n",
      "PSNR: -72.8763427734375\n",
      "Train Epoch: 163 [224/437 (50%)]\tLoss: 0.469217\n",
      "SSIM: 0.4445231258869171\n",
      "PSNR: -72.76490020751953\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 164 [0/437 (0%)]\tLoss: 0.478611\n",
      "SSIM: 0.45045313239097595\n",
      "PSNR: -72.47879028320312\n",
      "Train Epoch: 164 [224/437 (50%)]\tLoss: 0.469536\n",
      "SSIM: 0.4438042938709259\n",
      "PSNR: -72.82427215576172\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 165 [0/437 (0%)]\tLoss: 0.477476\n",
      "SSIM: 0.45122602581977844\n",
      "PSNR: -72.43995666503906\n",
      "Train Epoch: 165 [224/437 (50%)]\tLoss: 0.466857\n",
      "SSIM: 0.44717711210250854\n",
      "PSNR: -72.89049530029297\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 166 [0/437 (0%)]\tLoss: 0.473713\n",
      "SSIM: 0.4565390348434448\n",
      "PSNR: -72.659423828125\n",
      "Train Epoch: 166 [224/437 (50%)]\tLoss: 0.478722\n",
      "SSIM: 0.4509480893611908\n",
      "PSNR: -72.48530578613281\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 167 [0/437 (0%)]\tLoss: 0.467899\n",
      "SSIM: 0.44577541947364807\n",
      "PSNR: -72.88892364501953\n",
      "Train Epoch: 167 [224/437 (50%)]\tLoss: 0.475973\n",
      "SSIM: 0.44721439480781555\n",
      "PSNR: -72.71656036376953\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 168 [0/437 (0%)]\tLoss: 0.475321\n",
      "SSIM: 0.4584519565105438\n",
      "PSNR: -72.44536590576172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 168 [224/437 (50%)]\tLoss: 0.478697\n",
      "SSIM: 0.44715338945388794\n",
      "PSNR: -72.61592102050781\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 169 [0/437 (0%)]\tLoss: 0.465614\n",
      "SSIM: 0.4535906910896301\n",
      "PSNR: -72.79193878173828\n",
      "Train Epoch: 169 [224/437 (50%)]\tLoss: 0.471884\n",
      "SSIM: 0.44829946756362915\n",
      "PSNR: -72.82455444335938\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 170 [0/437 (0%)]\tLoss: 0.468934\n",
      "SSIM: 0.4599275290966034\n",
      "PSNR: -72.67851257324219\n",
      "Train Epoch: 170 [224/437 (50%)]\tLoss: 0.469037\n",
      "SSIM: 0.4403989315032959\n",
      "PSNR: -72.94453430175781\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 171 [0/437 (0%)]\tLoss: 0.479817\n",
      "SSIM: 0.45834311842918396\n",
      "PSNR: -72.30404663085938\n",
      "Train Epoch: 171 [224/437 (50%)]\tLoss: 0.465901\n",
      "SSIM: 0.45313796401023865\n",
      "PSNR: -72.80198669433594\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 172 [0/437 (0%)]\tLoss: 0.468032\n",
      "SSIM: 0.4572947025299072\n",
      "PSNR: -72.69845581054688\n",
      "Train Epoch: 172 [224/437 (50%)]\tLoss: 0.469107\n",
      "SSIM: 0.4562142789363861\n",
      "PSNR: -72.74681091308594\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 173 [0/437 (0%)]\tLoss: 0.470364\n",
      "SSIM: 0.45138517022132874\n",
      "PSNR: -72.71692657470703\n",
      "Train Epoch: 173 [224/437 (50%)]\tLoss: 0.476354\n",
      "SSIM: 0.45228567719459534\n",
      "PSNR: -72.4678955078125\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 174 [0/437 (0%)]\tLoss: 0.472207\n",
      "SSIM: 0.4564872980117798\n",
      "PSNR: -72.67903137207031\n",
      "Train Epoch: 174 [224/437 (50%)]\tLoss: 0.473518\n",
      "SSIM: 0.44915273785591125\n",
      "PSNR: -72.67231750488281\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 175 [0/437 (0%)]\tLoss: 0.470542\n",
      "SSIM: 0.45544159412384033\n",
      "PSNR: -72.71182250976562\n",
      "Train Epoch: 175 [224/437 (50%)]\tLoss: 0.473680\n",
      "SSIM: 0.4435007572174072\n",
      "PSNR: -72.88389587402344\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 176 [0/437 (0%)]\tLoss: 0.467538\n",
      "SSIM: 0.4510723650455475\n",
      "PSNR: -72.79193878173828\n",
      "Train Epoch: 176 [224/437 (50%)]\tLoss: 0.469017\n",
      "SSIM: 0.4543960690498352\n",
      "PSNR: -72.66922760009766\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 59]\n",
      "Train Epoch: 177 [0/437 (0%)]\tLoss: 0.473212\n",
      "SSIM: 0.4545672535896301\n",
      "PSNR: -72.60789489746094\n",
      "Train Epoch: 177 [224/437 (50%)]\tLoss: 0.467601\n",
      "SSIM: 0.45082324743270874\n",
      "PSNR: -72.84334564208984\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 178 [0/437 (0%)]\tLoss: 0.472380\n",
      "SSIM: 0.45689812302589417\n",
      "PSNR: -72.60440063476562\n",
      "Train Epoch: 178 [224/437 (50%)]\tLoss: 0.474362\n",
      "SSIM: 0.4529576897621155\n",
      "PSNR: -72.56561279296875\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 179 [0/437 (0%)]\tLoss: 0.468497\n",
      "SSIM: 0.4595286250114441\n",
      "PSNR: -72.63583374023438\n",
      "Train Epoch: 179 [224/437 (50%)]\tLoss: 0.467930\n",
      "SSIM: 0.45528697967529297\n",
      "PSNR: -72.76741790771484\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 92, 47, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 180 [0/437 (0%)]\tLoss: 0.460360\n",
      "SSIM: 0.4566057026386261\n",
      "PSNR: -72.92329406738281\n",
      "Train Epoch: 180 [224/437 (50%)]\tLoss: 0.473514\n",
      "SSIM: 0.4527767598628998\n",
      "PSNR: -72.6508560180664\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 181 [0/437 (0%)]\tLoss: 0.473456\n",
      "SSIM: 0.4520989954471588\n",
      "PSNR: -72.5246353149414\n",
      "Train Epoch: 181 [224/437 (50%)]\tLoss: 0.467805\n",
      "SSIM: 0.462086945772171\n",
      "PSNR: -72.5318832397461\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 182 [0/437 (0%)]\tLoss: 0.472928\n",
      "SSIM: 0.45013925433158875\n",
      "PSNR: -72.49949645996094\n",
      "Train Epoch: 182 [224/437 (50%)]\tLoss: 0.473064\n",
      "SSIM: 0.4532591998577118\n",
      "PSNR: -72.52183532714844\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 183 [0/437 (0%)]\tLoss: 0.467708\n",
      "SSIM: 0.4438866376876831\n",
      "PSNR: -72.89867401123047\n",
      "Train Epoch: 183 [224/437 (50%)]\tLoss: 0.475291\n",
      "SSIM: 0.45527929067611694\n",
      "PSNR: -72.5875473022461\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 184 [0/437 (0%)]\tLoss: 0.470500\n",
      "SSIM: 0.4506078362464905\n",
      "PSNR: -72.60262298583984\n",
      "Train Epoch: 184 [224/437 (50%)]\tLoss: 0.474267\n",
      "SSIM: 0.4542244076728821\n",
      "PSNR: -72.59734344482422\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 185 [0/437 (0%)]\tLoss: 0.472926\n",
      "SSIM: 0.45799440145492554\n",
      "PSNR: -72.50994873046875\n",
      "Train Epoch: 185 [224/437 (50%)]\tLoss: 0.480504\n",
      "SSIM: 0.4413008987903595\n",
      "PSNR: -72.5955810546875\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 186 [0/437 (0%)]\tLoss: 0.465331\n",
      "SSIM: 0.45916450023651123\n",
      "PSNR: -72.86145782470703\n",
      "Train Epoch: 186 [224/437 (50%)]\tLoss: 0.473843\n",
      "SSIM: 0.4461761713027954\n",
      "PSNR: -72.706787109375\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 187 [0/437 (0%)]\tLoss: 0.471705\n",
      "SSIM: 0.45696988701820374\n",
      "PSNR: -72.69305419921875\n",
      "Train Epoch: 187 [224/437 (50%)]\tLoss: 0.473630\n",
      "SSIM: 0.45195239782333374\n",
      "PSNR: -72.71651458740234\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 8, 72, 31, 79]\n",
      "Train Epoch: 188 [0/437 (0%)]\tLoss: 0.467308\n",
      "SSIM: 0.4587287902832031\n",
      "PSNR: -72.6710433959961\n",
      "Train Epoch: 188 [224/437 (50%)]\tLoss: 0.467061\n",
      "SSIM: 0.44870150089263916\n",
      "PSNR: -72.63706970214844\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 189 [0/437 (0%)]\tLoss: 0.468525\n",
      "SSIM: 0.4531651735305786\n",
      "PSNR: -72.77873229980469\n",
      "Train Epoch: 189 [224/437 (50%)]\tLoss: 0.467585\n",
      "SSIM: 0.4524726867675781\n",
      "PSNR: -72.83244323730469\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 190 [0/437 (0%)]\tLoss: 0.470742\n",
      "SSIM: 0.4514824450016022\n",
      "PSNR: -72.8480224609375\n",
      "Train Epoch: 190 [224/437 (50%)]\tLoss: 0.465778\n",
      "SSIM: 0.45555394887924194\n",
      "PSNR: -72.79911804199219\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 191 [0/437 (0%)]\tLoss: 0.472410\n",
      "SSIM: 0.4504007399082184\n",
      "PSNR: -72.7681655883789\n",
      "Train Epoch: 191 [224/437 (50%)]\tLoss: 0.467184\n",
      "SSIM: 0.4594895541667938\n",
      "PSNR: -72.82476806640625\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 192 [0/437 (0%)]\tLoss: 0.475256\n",
      "SSIM: 0.4492473602294922\n",
      "PSNR: -72.61981201171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 192 [224/437 (50%)]\tLoss: 0.468519\n",
      "SSIM: 0.45286402106285095\n",
      "PSNR: -72.77509307861328\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 193 [0/437 (0%)]\tLoss: 0.472536\n",
      "SSIM: 0.4535313844680786\n",
      "PSNR: -72.5427474975586\n",
      "Train Epoch: 193 [224/437 (50%)]\tLoss: 0.466753\n",
      "SSIM: 0.4585776627063751\n",
      "PSNR: -72.6785888671875\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 194 [0/437 (0%)]\tLoss: 0.476032\n",
      "SSIM: 0.4472857713699341\n",
      "PSNR: -72.58843231201172\n",
      "Train Epoch: 194 [224/437 (50%)]\tLoss: 0.467550\n",
      "SSIM: 0.4582333266735077\n",
      "PSNR: -72.81259155273438\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 18, 67, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 195 [0/437 (0%)]\tLoss: 0.475171\n",
      "SSIM: 0.45364436507225037\n",
      "PSNR: -72.48326110839844\n",
      "Train Epoch: 195 [224/437 (50%)]\tLoss: 0.475009\n",
      "SSIM: 0.453791081905365\n",
      "PSNR: -72.70532989501953\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 196 [0/437 (0%)]\tLoss: 0.469920\n",
      "SSIM: 0.45241779088974\n",
      "PSNR: -72.77761840820312\n",
      "Train Epoch: 196 [224/437 (50%)]\tLoss: 0.470678\n",
      "SSIM: 0.44460180401802063\n",
      "PSNR: -72.85492706298828\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 197 [0/437 (0%)]\tLoss: 0.468508\n",
      "SSIM: 0.45506319403648376\n",
      "PSNR: -72.84171295166016\n",
      "Train Epoch: 197 [224/437 (50%)]\tLoss: 0.473651\n",
      "SSIM: 0.45495274662971497\n",
      "PSNR: -72.37812042236328\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 79]\n",
      "Train Epoch: 198 [0/437 (0%)]\tLoss: 0.476042\n",
      "SSIM: 0.44394707679748535\n",
      "PSNR: -72.6766128540039\n",
      "Train Epoch: 198 [224/437 (50%)]\tLoss: 0.469754\n",
      "SSIM: 0.4576927721500397\n",
      "PSNR: -72.67183685302734\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n",
      "Train Epoch: 199 [0/437 (0%)]\tLoss: 0.481086\n",
      "SSIM: 0.45613735914230347\n",
      "PSNR: -72.3813705444336\n",
      "Train Epoch: 199 [224/437 (50%)]\tLoss: 0.470364\n",
      "SSIM: 0.4497842490673065\n",
      "PSNR: -72.6514663696289\n",
      "Top 30 bands with Entropy -> [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "import kornia\n",
    "global bsnlist\n",
    "ssim = kornia.losses.SSIMLoss(5, reduction='none')\n",
    "psnr = kornia.losses.PSNRLoss(2500)\n",
    "from skimage import measure\n",
    "ssim_list = []\n",
    "psnr_list = []\n",
    "l1_list = []\n",
    "channel_weight_list = []\n",
    "def train(epoch):    \n",
    "    model.train()\n",
    "    ENTROPY = torch.zeros(128)\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data[\"image\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output =  model(data)\n",
    "        loss = F.l1_loss(output,data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        D = output.detach().cpu().numpy()\n",
    "        for i in range(0,128):\n",
    "\n",
    "          ENTROPY[i]+=skimage.measure.shannon_entropy(D[:,i,:,:])\n",
    "        \n",
    "        if batch_idx % (0.5*len(train_loader)) == 0:\n",
    "\n",
    "\n",
    "\n",
    "            L1 = loss.item()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),L1))\n",
    "            l1_list.append(L1)\n",
    "            ssim_val = torch.mean(ssim(data,output))\n",
    "            print(\"SSIM: {}\".format(ssim_val))\n",
    "            ssim_list.append(ssim_val)\n",
    "            psnr_val = psnr(data,output)\n",
    "            print(\"PSNR: {}\".format(psnr_val))\n",
    "            psnr_list.append(psnr_val)\n",
    "        \n",
    "        \n",
    "    ENTROPY = np.array(ENTROPY)\n",
    "    bsnlist = np.asarray(ENTROPY.argsort()[-top:][::-1])\n",
    "    print('Top {} bands with Entropy ->'.format(top),list(bsnlist))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "for epoch in range(0, 200):\n",
    "    train(epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSSV4CP6HhSU"
   },
   "outputs": [],
   "source": [
    "bsnlist = [69, 66, 93, 86, 78, 77, 73, 70, 52, 108]\n",
    "#bsnlist = [103, 58, 74, 122, 39, 91, 38, 67, 18, 63, 50, 42, 114, 15, 16, 89, 107, 40, 96, 29, 47, 92, 13, 124, 46, 44, 72, 8, 31, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gVz0NjFVC-zQ",
    "outputId": "d9647d4b-e09b-41aa-b4c1-217b5eff697a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "x,xx,xxx = psnr_list,ssim_list,l1_list\n",
    "print(len(x)),print(len(xx)),print(len(xxx))\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-76.2489, device='mps:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "JYtFsHDPDav6",
    "outputId": "64a22623-56bd-4b6b-a923-2dc4170e2e4f"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39myticks(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100\u001b[39m , \u001b[38;5;241m10.0\u001b[39m),fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSNR-IN.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/matplotlib/pyplot.py:2767\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2768\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2769\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1635\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1635\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/matplotlib/axes/_base.py:490\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 490\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mindex_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mupdate_units(x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1619\u001b[0m, in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1619\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;66;03m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[1;32m   1622\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1311\u001b[0m, in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;66;03m# Note this will strip unit information.\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m         \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/numpy/core/shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[0;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adlproject/lib/python3.8/site-packages/torch/_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Epoch',fontsize=50)\n",
    "plt.ylabel('PSNR',fontsize=50)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(np.arange(0,100 , 10.0),fontsize=40)\n",
    "plt.ylim(10,100)\n",
    "plt.plot(x,linewidth=5.0)\n",
    "plt.savefig('PSNR-IN.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "colab_type": "code",
    "id": "zTN88wHTDeP6",
    "outputId": "1e31015c-3a8e-40ae-ab16-f6ab2b5b2795"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Epoch',fontsize=50)\n",
    "plt.ylabel('SSIM',fontsize=50)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.plot(xx,linewidth=5.0)\n",
    "plt.savefig('SSIM-IN.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "colab_type": "code",
    "id": "brWW-10UDhru",
    "outputId": "22ac3bfe-cf3a-4021-9376-170a17231b0c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Epoch',fontsize=50)\n",
    "plt.ylabel('L1 Reconstruction loss',fontsize=50)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.plot(xxx,linewidth=5.0)\n",
    "plt.savefig('L1-IN.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxJCSLj2W-mq"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wVzMictDuad"
   },
   "outputs": [],
   "source": [
    "def MeanSpectralDivergence(band_subset):\n",
    "\n",
    "  n_row, n_column, n_band = band_subset.shape\n",
    "  N = n_row * n_column\n",
    "  hist = []\n",
    "  for i in range(n_band):\n",
    "    hist_, _ = np.histogram(band_subset[:, :, i], 256)\n",
    "    hist.append(hist_ / N)\n",
    "  hist = np.asarray(hist)\n",
    "  hist[np.nonzero(hist <= 0)] = 1e-20  \n",
    "  info_div = 0  \n",
    "  for b_i in range(n_band):\n",
    "    for b_j in range(n_band):\n",
    "      band_i = hist[b_i].reshape(-1)/np.sum(hist[b_i])\n",
    "      band_j = hist[b_j].reshape(-1)/np.sum(hist[b_j])\n",
    "      entr_ij = entropy(band_i, band_j)\n",
    "      entr_ji = entropy(band_j, band_i)\n",
    "      entr_sum = entr_ij + entr_ji\n",
    "      info_div += entr_sum\n",
    "  msd = info_div * 2 / (n_band * (n_band - 1))\n",
    "  return msd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZeRRCfAzDwUY"
   },
   "outputs": [],
   "source": [
    "def MeanSpectralAngle(band_subset):\n",
    "    \"\"\"\n",
    "    Spectral Angle (SA) is defined as the angle between two bands.\n",
    "    We use Mean SA (MSA) to quantify the redundancy among a band set.\n",
    "    i-th band B_i, and j-th band B_j,\n",
    "    SA = arccos [B_i^T * B_j / ||B_i|| * ||B_j||]\n",
    "    MSA = 2/n*(n-1) * sum(SA_ij)\n",
    "    Ref:\n",
    "    [1]\tGONG MAOGUO, ZHANG MINGYANG, YUAN YUAN. Unsupervised Band Selection Based on Evolutionary Multiobjective\n",
    "    Optimization for Hyperspectral Images [J]. IEEE Transactions on Geoscience and Remote Sensing, 2016, 54(1): 544-57.\n",
    "    :param band_subset: with shape (n_row, n_clm, n_band)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n_row, n_column, n_band = band_subset.shape\n",
    "    spectral_angle = 0\n",
    "    for i in range(n_band):\n",
    "        for j in range(n_band):\n",
    "            band_i = band_subset[i].reshape(-1)\n",
    "            band_j = band_subset[j].reshape(-1)\n",
    "            lower = np.sum(band_i ** 2) ** 0.5 * np.sum(band_j ** 2) ** 0.5\n",
    "            higher = np.dot(band_i, band_j)\n",
    "            if higher / lower > 1.:\n",
    "                angle_ij = np.arccos(1. - 1e-16)\n",
    "                # print('1-higher-lower', higher - lower)\n",
    "            # elif higher / lower < -1.:\n",
    "            #     angle_ij = np.arccos(1e-8 - 1.)\n",
    "                # print('2-higher-lower', higher - lower)\n",
    "            else:\n",
    "                angle_ij = np.arccos(higher / lower)\n",
    "            spectral_angle += angle_ij\n",
    "    msa = spectral_angle * 2 / (n_band * (n_band - 1))\n",
    "    return msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "075nd2hQDzVY"
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import measure\n",
    "def sumentr(band_subset,X):\n",
    "  nbands = len(band_subset)\n",
    "  ENTROPY=np.ones(nbands)\n",
    "  for i in range(0,len(band_subset)):\n",
    "    ENTROPY[i]+=skimage.measure.shannon_entropy(X[:,:,band_subset[i]])\n",
    "  return np.sum(ENTROPY)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgMa8W9nD3Ch"
   },
   "outputs": [],
   "source": [
    "def MSA(bsnlist):\n",
    "  X, _ = loadData()\n",
    "  print('[',end=\" \")\n",
    "  for a in range(2,len(bsnlist)):\n",
    "    band_subset_list = []\n",
    "    for i in bsnlist[:a]:\n",
    "      band_subset_list.append(X[:,:,i])     \n",
    "    band_subset = np.array(band_subset_list)\n",
    "    band_subset = np.stack(band_subset,axis =2)\n",
    "    print(MeanSpectralAngle(band_subset),end=\" \")\n",
    "    if a!= len(bsnlist)-1:\n",
    "      print(\",\",end=\" \")\n",
    "  print(']')\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLhGFydrD7Zb"
   },
   "outputs": [],
   "source": [
    "def MSD(bsnlist):\n",
    "  X, _ = loadData()\n",
    "  print('[',end=\" \")\n",
    "  for a in range(2,len(bsnlist)):\n",
    "    band_subset_list = []\n",
    "    for i in bsnlist[:a]:\n",
    "      band_subset_list.append(X[:,:,i])     \n",
    "    band_subset = np.array(band_subset_list)\n",
    "    band_subset = np.stack(band_subset,axis =2)\n",
    "    print(MeanSpectralDivergence(band_subset),end=\" \")\n",
    "    if a!= len(bsnlist)-1:\n",
    "      print(\",\",end=\" \")\n",
    "  print(']')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5S32wY-D-zu"
   },
   "outputs": [],
   "source": [
    "def EntropySum(bsnlist):\n",
    "  X, _ = loadData()\n",
    "  print('[',end=\" \")\n",
    "  for a in range(2,len(bsnlist)):\n",
    "    band_subset_list = []\n",
    "    for i in bsnlist[:a]:\n",
    "      band_subset_list.append(X[:,:,i])     \n",
    "    band_subset = np.array(band_subset_list)\n",
    "    band_subset = np.stack(band_subset,axis =2)\n",
    "    print(sumentr(bsnlist[:a],X),end=\" \")\n",
    "    if a!= len(bsnlist)-1:\n",
    "      print(\",\",end=\" \")\n",
    "  print(']')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "q9Lw7e2RD_8z",
    "outputId": "655ec35c-d98b-4e00-8e92-85fa99683b19"
   },
   "outputs": [],
   "source": [
    "MSA(bsnlist)\n",
    "MSD(bsnlist)\n",
    "EntropySum(bsnlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "colab_type": "code",
    "id": "oKpCv411H2uU",
    "outputId": "a489430e-9c03-458c-8264-440b5304e879"
   },
   "outputs": [],
   "source": [
    "dabs = [ 33.12881252113703 , 27.699269748852547 , 31.189050523240567 , 25.407158521806743 , 21.23842365661258 , 21.4600299169822 , 20.86248085946583 , 20.17228040657472 , 20.53299041484558 , 21.1335634998955 , 19.59117061832842 , 20.946230004039375 , 22.843494279707382 , 21.596483466175062 , 21.633130554147392 , 22.832050045391185 , 23.112561570936894 , 23.938250673675114 , 24.27697303727743 , 24.67049003424132 , 24.818116958133697 , 24.450204537801287 , 25.019421764795172 ]\n",
    "bsnetconv = [ 24.926582298710684 , 21.330938461786815 , 23.04076040826106 , 21.645181998356264 , 18.691557180047244 , 20.7226257192415 , 20.180950404677475 , 18.92119239091796 , 18.14126793229048 , 18.054941145300337 , 19.2913419518319 , 21.458442690479096 , 22.376986846120094 , 26.539316782854403 , 26.364677531292276 , 26.004356791026886 , 26.06563007931373 , 27.562615680165703 , 26.816233958923476 , 26.75423730463073 , 26.76546728344344 , 26.651876628889074 , 26.170407693767313 ]\n",
    "pca = [ 64.6659495569616 , 44.206964175291155 , 56.974405048963185 , 47.303760042785385 , 39.8940534876976 , 34.768743086455515 , 30.563590015282664 , 27.347606401064958 , 25.73579551531729 , 23.562059922897653 , 24.332531206971105 , 22.65318676880641 , 21.20680313199034 , 19.950365482269632 , 18.7957381872366 , 17.785780071254095 , 16.84197341100759 , 16.71704973304585 , 15.959359012341034 , 16.69296720295007 , 16.303398054778945 , 15.775575036839665 , 15.247189808858215 ]\n",
    "spabs = [ 51.546751478947485 , 41.56190968855882 , 34.1507585379382 , 32.18755647433454 , 31.393008047463585 , 31.02527459658134 , 30.212480943960397 , 33.42180148091237 , 32.627589457381625 , 30.811290451152864 , 31.07497311582388 , 29.193101794721112 , 28.174085856682574 , 27.110556610241026 , 26.16396012024104 , 27.642474793195948 , 26.97927639524588 , 26.802185442574 , 26.733570979934218 , 25.614498829087168 , 24.57496106936372 , 24.260774948635653 , 24.535411090068447 ]\n",
    "snmf = [ 42.687271482734026 , 69.98650272134581 , 65.56190884814379 , 64.78830503377719 , 60.283392581094056 , 57.29725635316855 , 61.48424023193987 , 65.9111624844873 , 69.81263992889625 , 66.0216268025207 , 63.44659867282022 , 59.12927876180595 , 55.89468878602123 , 54.131703617998376 , 56.680276749080825 , 59.53217131059314 , 57.16351130033321 , 54.9461367723193 , 55.23628180002861 , 54.62510055278423 , 53.74485500301176 , 52.97448803455957 , 51.9084356071723 ]\n",
    "issc = [ 18.282704191681795 , 35.29174781838125 , 33.52621667208111 , 34.7570094214297 , 34.693446545983406 , 33.8470987598166 , 42.36183874938314 , 38.34479910743488 , 38.34974051412382 , 35.28287700260462 , 32.65494379097696 , 32.312139823186655 , 30.307662525527835 , 29.98966839606608 , 29.269512799967384 , 29.912423244699333 , 29.038917745855983 , 28.929037072912795 , 28.672306590798843 , 28.505889476998565 , 28.182865736586837 , 28.759689061354372 , 28.95934175252772 ]\n",
    "new = [ 0.3815454878000646 , 6.781090755133797 , 9.950440828878444 , 11.237053937027174 , 27.088203156192495 , 28.32426713263673 , 31.61098768365176 , 29.18215151414016 , 30.623415605281778 , 28.31521833089382 , 27.449306705475106 , 26.808790797203535 , 26.64422017203365 , 26.15949242450031 , 24.537110949551423 , 26.60549266437586 , 25.726471570464867 , 25.336850074623072 , 24.637817130631845 , 23.95399234128613 , 23.29746143739684 , 22.647506727415077 , 22.878749722275444 ]\n",
    "NSBands = list((i for i in range(2,25)))\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "methods = [dabs,bsnetconv,pca,spabs,snmf,new]\n",
    "for i in methods:  print(len(i))\n",
    "markerstylelist = [\"8\",\"1\",\"2\",\"4\",\"*\",\"3\",\"5\"]\n",
    "scatar = []\n",
    "f = plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "for method in methods:\n",
    "  PLOT = plt.plot(NSBands,method,markersize=30)\n",
    "  SCATTER = plt.scatter(NSBands,method,s=100)\n",
    "  scatar.append(SCATTER)\n",
    "plt.xlabel('Number of Selected Bands',fontsize=40)\n",
    "plt.ylabel('MSD',fontsize=40)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.ylim(1,80)\n",
    "plt.xlim(1,25)\n",
    "plt.legend(scatar,['DARecNet-BS','BSNet-Conv','PCA','SpaBS','SNMF','New'],loc='best',fontsize='xx-large',shadow=True,prop={'size': 26},bbox_to_anchor=(0.5, 0.5, 0.5, 0.5))\n",
    "plt.show()\n",
    "f.savefig(\"MSD-IN.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOMA2sjbYBmb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Pytorch BSNetConv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
